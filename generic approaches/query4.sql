package com.anthem.etl.cii.daoimport java.time.LocalDateTimeimport java.time.format.DateTimeFormatterimport scala.collection.mutable.ListBufferimport scala.collection.JavaConverters.import org.apache.spark.sql.SaveModeimport org.apache.spark.sql.DataFrameimport org.apache.spark.sql.functions.import org.apache.spark.sql.functions.litimport org.apache.spark.sql.types.import org.apache.spark.sql.types.StructTypeimport org.apache.spark.sql.types.TimestampTypeimport com.anthem.etl.cii.util.import org.apache.spark.storage.StorageLevelimport com.anthem.etl.dao.import org.apache.spark.sql.expressions.Windowimport org.apache.spark.sql.functions.upperimport org.apache.spark.sql.functions.trimimport org.apache.spark.sql.functions.currenttimestampimport java.net.URIimport com.amazonaws.AmazonServiceException;
import com.amazonaws.regions.Regions;
import com.amazonaws.services.s.AmazonS;
import com.amazonaws.services.s.AmazonSClientBuilder;
class WorkAccntSgmntXwalkDAO extends DataSFAccessObject  override def importData(aDataSrcCfg DataSourceSFConfig, aSchemaDef StructType) DataFrame = val sqlContext = getSparkSession.sqlContextimport sqlContext.implicits.val env = aDataSrcCfg.envval release = aDataSrcCfg.releaseval layer = aDataSrcCfg.layerval dbnamegbd = s    val dbname = s    val dbnamecdl = s    val dbnameadhoc = svar sqls = ArrayString()aDataSrcCfg.queryMap.asScala foreach (sqlFileMap = sqls = sqlFileMap..split())val dfRLTNSHP = broadcast(getSparkSession.sql(getFileContent(aDataSrcCfg.environment.concat().concat(sqls())).replace(, aDataSrcCfg.env).replace(, aDataSrcCfg.release).replace(, aDataSrcCfg.layer)))val dfwrk= getSparkSession.table(s)val SCDRLTNSHP= getSparkSession.table(s).as()          .join(dfRLTNSHP.as(),  === )          .where(trim()===)          .where(.isin(,,))          .select(trim().as(),trim().as(),  trim().as(),trim().as())        val  SCDRLTNSHPGRP=broadcast(SCDRLTNSHP.filter(=== ))         val  SCDRLTNSHPCLNT=broadcast(SCDRLTNSHP.filter(=== ))          val  SCDRLTNSHPASSN=broadcast(SCDRLTNSHP.filter(=== ))val FRAME= dfwrk.as().join(SCDRLTNSHPGRP.as(), ===               === )                                        .select(                                                                               ,                                       ,                                       ,                                       ,                                       ,                                       ,                                       ,                                       ,.as()                                       ,                                       ,                                       ,.as()                         ,                      ,.as()                      ,                      ,                      ,                      ,                      ,                      ,                      ,                      ,                      ,                      ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,              ,              ,              ,              ,              ,              ,              ,              ,              ,              ,)val FRAME= dfwrk.as() .join(SCDRLTNSHPCLNT.as(), ===               === ).select(                                                                               ,                                       ,                                       ,                                       ,                                       ,                                       ,                                       ,                                       ,.as()                                       ,                                       ,                                       ,.as()                         ,                      ,.as()                      ,                      ,                      ,                      ,                      ,                      ,                      ,                      ,                      ,                      ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,            ,            ,            ,            ,            ,            ,            ,            ,            ,              ,)val FRAME= dfwrk.as().join(SCDRLTNSHPASSN.as(), ===               === ).select(                                                                               ,                                       ,                                       ,                                       ,                                       ,                                       ,                                       ,                                       ,.as()                                       ,                                       ,                                       ,.as()                         ,                      ,.as()                      ,                      ,                      ,                      ,                      ,                      ,                      ,                      ,                      ,                      ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,            ,            ,            ,            ,            ,            ,            ,            ,            ,             ,)val FRAME =  FRAME.unionAll(FRAME).unionAll(FRAME)val scdorg= getSparkSession.sql(getFileContent(aDataSrcCfg.environment.concat().concat(sqls())).replace(, aDataSrcCfg.env).replace(, aDataSrcCfg.release).replace(, aDataSrcCfg.layer))   val FRAME= FRAME.as().join(broadcast(scdorg).as(),=== ,)            .withColumn(,when(.isNotNull,).otherwise(lit()))            .withColumn(,when(.isNotNull,).otherwise(lit())).select(                          ,                          ,                          ,                          ,                          ,                          ,                          ,                          ,                            ,                          ,when(.isin(,,,,,,)  .isNull,).otherwise(upper(trim(regexpreplace(,, )))).as()                          ,                          ,                         ,                          ,.as()                        ,,,,,,.as(),,,,when(.isin(,,,,,,)  .isNull,).otherwise(upper(trim(regexpreplace(,, )))).as(),when(.isin(,,,,,,)  .isNull,).otherwise(upper(trim(regexpreplace(,, )))).as(),,,,,,,,,,,,,,,,,.as(),,,,,,,,.as(),,            ,            ,            ,            ,            ,            ,            ,            ,            ,            ,).distinct()  CIIUtilities.writeDFtoS(aDataSrcCfg,FRAME,)  val framenew =CIIUtilities.readDFfromS(aDataSrcCfg,)  framenew.createOrReplaceTempView()  val mstrsgmntelgbl= broadcast(getSparkSession.sql(getFileContent(aDataSrcCfg.environment.concat().concat(sqls())).replace(, aDataSrcCfg.env).replace(, aDataSrcCfg.release).replace(, aDataSrcCfg.layer)))   mstrsgmntelgbl.createOrReplaceTempView()  val WORKGRPSGMNTNUSEDtbl= broadcast(getSparkSession.table(s))  WORKGRPSGMNTNUSEDtbl.createOrReplaceTempView()  val FinalErsu= getSparkSession.sql(getFileContent(aDataSrcCfg.environment.concat().concat(sqls())).replace(, aDataSrcCfg.env).replace(, aDataSrcCfg.release).replace(, aDataSrcCfg.layer))   val FinalErsuFinal= FinalErsu.withColumn(, typedLit(currenttimestamp).cast(TimestampType))    .withColumn(, lit(aDataSrcCfg.loadlogkey))  val dfacctsgmntntMbrStg= castColumnTypes(FinalErsuFinal, aSchemaDef)  dfacctsgmntntMbrStg;
